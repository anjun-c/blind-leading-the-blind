<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>UNBLIND</title>
</head>
<body>
  <h1>UNBLIND</h1>
  
  <!-- Voice Recording Section -->
  <section>
    <h2>Voice Recording (WebSocket Streaming)</h2>
    <button id="voiceRecordBtn">Start Voice Recording</button>
    <p id="voiceStatus"></p>
    <h3>Transcription:</h3>
    <div id="transcriptionOutput" style="border:1px solid #ccc; padding: 8px; min-height: 40px;"></div>
  </section>
  
  <!-- Video Recording Section -->
  <section>
    <h2>Video Recording (WebSocket Streaming)</h2>
    <!-- This button is still available in case you want to manually toggle -->
    <button id="videoRecordBtn">Start Video Recording</button>
    <p id="videoStatus"></p>
    <h3>Processed Video Frame:</h3>
    <img id="processedFrame" width="320" height="240" alt="Processed Video Frame" style="border:1px solid #ccc;">
  </section>
  
  <script>
    // Global variables for voice streaming
    let voiceRecorder;
    let voiceRecording = false;
    let voiceSocket; // WebSocket for audio streaming
    let voiceStream;

    // Global variables for video streaming
    let videoRecorder;
    let videoRecording = false;
    let videoSocket; // WebSocket for video streaming
    let videoStream;

    const voiceRecordBtn = document.getElementById('voiceRecordBtn');
    const voiceStatus = document.getElementById('voiceStatus');
    const transcriptionOutput = document.getElementById('transcriptionOutput');
    
    const videoRecordBtn = document.getElementById('videoRecordBtn');
    const videoStatus = document.getElementById('videoStatus');
    const processedFrame = document.getElementById('processedFrame');

    // --- Voice Recording Logic ---
    voiceRecordBtn.addEventListener('click', async () => {
      if (!voiceRecording) {
        // Request audio stream once
        voiceStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // Open WebSocket connection to the backend endpoint
        voiceSocket = new WebSocket('ws://127.0.0.1:8000/ws/stream_audio');
        voiceSocket.onopen = () => {
          console.log('Voice WebSocket connection opened');
          voiceStatus.innerText = 'Streaming audio...';
        };
        voiceSocket.onerror = (err) => {
          console.error('Voice WebSocket error: ', err);
          voiceStatus.innerText = 'Error in audio stream.';
        };
        voiceSocket.onclose = () => {
          console.log('Voice WebSocket connection closed');
        };
        // Listen for transcription messages from the server
        voiceSocket.onmessage = (event) => {
          const transcription = event.data;
          transcriptionOutput.innerText = transcription;
          
          // Check for control phrases (case-insensitive)
          if (transcription.toUpperCase().includes("ECHO") && !videoRecording) {
            console.log("Detected 'ECHO'");
            startVideoStream();
          }
          if (transcription.toUpperCase().includes("STOP") && videoRecording) {
            console.log("Detected 'STOP'");
            stopVideoStream();
          }
        };
        
        voiceRecording = true;
        voiceRecordBtn.innerText = 'Stop Voice Recording';
        startVoiceRecordingCycle();
      } else {
        // Stop the voice cycle and close the WebSocket
        voiceRecording = false;
        if (voiceRecorder && voiceRecorder.state !== "inactive") {
          voiceRecorder.stop();
        }
        if (voiceSocket && voiceSocket.readyState === WebSocket.OPEN) {
          voiceSocket.close();
        }
        voiceRecordBtn.innerText = 'Start Voice Recording';
        voiceStatus.innerText = 'Audio streaming stopped.';
      }
    });

    // Function for a recording cycle: record for a fixed duration (3 sec), send blob, then restart
    function startVoiceRecordingCycle() {
      if (!voiceRecording) return;
      
      // Specify MIME type explicitly to encourage a complete container.
      voiceRecorder = new MediaRecorder(voiceStream, { mimeType: "audio/webm;codecs=opus" });
      
      voiceRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && voiceSocket.readyState === WebSocket.OPEN) {
          voiceSocket.send(event.data);
        }
      };

      // When the recorder stops, restart the cycle if still recording.
      voiceRecorder.onstop = () => {
        if (voiceRecording) {
          setTimeout(startVoiceRecordingCycle, 200);
        }
      };

      // Record for 3 seconds
      voiceRecorder.start();
      setTimeout(() => {
        if (voiceRecorder.state === "recording") {
          voiceRecorder.stop();
        }
      }, 3000);
    }

    // --- Video Recording Logic ---
    async function startVideoStream() {
      if (videoRecording) return;
      videoStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      videoSocket = new WebSocket('ws://127.0.0.1:8000/ws/stream_video');
      videoSocket.onopen = () => {
        console.log('Video WebSocket connection opened');
        videoStatus.innerText = 'Streaming video...';
      };
      videoSocket.onerror = (err) => {
        console.error('Video WebSocket error: ', err);
        videoStatus.innerText = 'Error in video stream.';
      };
      videoSocket.onclose = () => {
        console.log('Video WebSocket connection closed');
      };

      videoSocket.onmessage = (event) => {
        const blob = new Blob([event.data], { type: 'image/jpeg' });
        const url = URL.createObjectURL(blob);
        processedFrame.src = url;
        setTimeout(() => {
          URL.revokeObjectURL(url);
        }, 100);
      };

      videoRecorder = new MediaRecorder(videoStream);
      videoRecorder.ondataavailable = (e) => {
        if (e.data.size > 0 && videoSocket.readyState === WebSocket.OPEN) {
          videoSocket.send(e.data);
        }
      };
      videoRecorder.start(1000);
      videoRecordBtn.innerText = 'Stop Video Recording';
      videoRecording = true;
    }

    function stopVideoStream() {
      if (videoRecorder) videoRecorder.stop();
      if (videoSocket && videoSocket.readyState === WebSocket.OPEN) {
        videoSocket.close();
      }
      videoRecordBtn.innerText = 'Start Video Recording';
      videoStatus.innerText = 'Video streaming stopped.';
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
      }
      processedFrame.src = '';
      videoRecording = false;
    }

    // Optional manual control for video recording via button click
    videoRecordBtn.addEventListener('click', async () => {
      if (!videoRecording) {
        await startVideoStream();
      } else {
        stopVideoStream();
      }
    });
  </script>
</body>
</html>
