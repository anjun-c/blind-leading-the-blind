<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>UNBLIND</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background: #f4f4f4;
      margin: 0;
      padding: 20px;
    }
    h1 {
      text-align: center;
      color: #333;
    }
    .container {
      display: flex;
      flex-wrap: wrap;
      justify-content: space-around;
      gap: 20px;
    }
    .section {
      background: #fff;
      padding: 20px;
      border-radius: 8px;
      flex: 1;
      min-width: 300px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    .section h2 {
      color: #444;
    }
    .section button {
      background: #007BFF;
      border: none;
      color: #fff;
      padding: 10px 20px;
      margin: 10px 0;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
    }
    .section button:hover {
      background: #0056b3;
    }
    #processedFrame {
      width: 640px;
      height: 480px;
      display: block;
      margin: 0 auto;
      border: 1px solid #ccc;
    }
    #transcriptionOutput {
      background: #e9e9e9;
      padding: 10px;
      border-radius: 4px;
      margin-top: 10px;
      min-height: 40px;
    }
  </style>
</head>
<body>
  <h1>UNBLIND</h1>
  <div class="container">
    <!-- Voice Recording Section -->
    <div class="section" id="voiceSection">
      <h2>Voice Recording (WebSocket Streaming)</h2>
      <button id="voiceRecordBtn">Start Voice Recording</button>
      <p id="voiceStatus"></p>
      <h3>Transcription:</h3>
      <div id="transcriptionOutput"></div>
    </div>
    
    <!-- Video Recording Section -->
    <div class="section" id="videoSection">
      <h2>Video Recording (WebSocket Streaming)</h2>
      <button id="videoRecordBtn">Start Video Recording</button>
      <p id="videoStatus"></p>
      <h3>Processed Video Frame:</h3>
      <img id="processedFrame" alt="Processed Video Frame">
    </div>
  </div>
  
  <script>
    // Global variables for voice streaming
    let voiceRecorder;
    let voiceRecording = false;
    let voiceSocket;
    let voiceStream;

    // Global variables for video streaming using canvas capture
    let videoRecording = false;
    let videoSocket;
    let videoStream;
    let videoCaptureInterval;
    let videoElement;

    const voiceRecordBtn = document.getElementById('voiceRecordBtn');
    const voiceStatus = document.getElementById('voiceStatus');
    const transcriptionOutput = document.getElementById('transcriptionOutput');
    
    const videoRecordBtn = document.getElementById('videoRecordBtn');
    const videoStatus = document.getElementById('videoStatus');
    const processedFrame = document.getElementById('processedFrame');

    // --- Voice Recording Logic ---
    voiceRecordBtn.addEventListener('click', async () => {
      if (!voiceRecording) {
        voiceStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        voiceSocket = new WebSocket('ws://127.0.0.1:8000/ws/stream_audio');
        voiceSocket.onopen = () => {
          console.log('Voice WebSocket connection opened');
          voiceStatus.innerText = 'Streaming audio...';
        };
        voiceSocket.onerror = (err) => {
          console.error('Voice WebSocket error: ', err);
          voiceStatus.innerText = 'Error in audio stream.';
        };
        voiceSocket.onclose = () => {
          console.log('Voice WebSocket connection closed');
        };
        voiceSocket.onmessage = (event) => {
          const transcription = event.data;
          console.log("Received transcription:", transcription);
          transcriptionOutput.innerText = transcription;
          // Control logic: if transcription contains control phrases
          if (transcription.toUpperCase().includes("ECHO") && !videoRecording) {
            console.log("Detected 'ECHO' - starting video stream");
            startVideoStream();
          }
          if (transcription.toUpperCase().includes("STOP") && videoRecording) {
            console.log("Detected 'STOP' - stopping video stream");
            stopVideoStream();
          }
        };
        
        voiceRecording = true;
        voiceRecordBtn.innerText = 'Stop Voice Recording';
        startVoiceRecordingCycle();
      } else {
        voiceRecording = false;
        if (voiceRecorder && voiceRecorder.state !== "inactive") {
          voiceRecorder.stop();
        }
        if (voiceSocket && voiceSocket.readyState === WebSocket.OPEN) {
          voiceSocket.close();
        }
        voiceRecordBtn.innerText = 'Start Voice Recording';
        voiceStatus.innerText = 'Audio streaming stopped.';
      }
    });

    function startVoiceRecordingCycle() {
      if (!voiceRecording) return;
      
      voiceRecorder = new MediaRecorder(voiceStream, { mimeType: "audio/webm;codecs=opus" });
      
      voiceRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && voiceSocket.readyState === WebSocket.OPEN) {
          console.log("Sending audio blob of size:", event.data.size);
          voiceSocket.send(event.data);
        }
      };

      voiceRecorder.onstop = () => {
        if (voiceRecording) {
          setTimeout(startVoiceRecordingCycle, 200);
        }
      };

      voiceRecorder.start();
      setTimeout(() => {
        if (voiceRecorder.state === "recording") {
          voiceRecorder.stop();
        }
      }, 3000);
    }

    // --- Video Recording Logic Using Canvas Capture ---
    async function startVideoStream() {
      if (videoRecording) return;
      videoStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      videoElement = document.createElement('video');
      videoElement.srcObject = videoStream;
      videoElement.play();
      console.log("Video element created and playing.");
      
      videoSocket = new WebSocket('ws://127.0.0.1:8000/ws/stream_video');
      videoSocket.onopen = () => {
        console.log('Video WebSocket connection opened');
        videoStatus.innerText = 'Streaming video...';
      };
      videoSocket.onerror = (err) => {
        console.error('Video WebSocket error: ', err);
        videoStatus.innerText = 'Error in video stream.';
      };
      videoSocket.onclose = () => {
        console.log('Video WebSocket connection closed');
      };

      videoSocket.onmessage = (event) => {
        console.log("Received processed video frame data, size:", event.data.byteLength);
        const blob = new Blob([event.data], { type: 'image/jpeg' });
        console.log("Created blob from processed frame, size:", blob.size);
        const url = URL.createObjectURL(blob);
        processedFrame.src = url;
        setTimeout(() => {
          console.log("Revoking URL:", url);
          URL.revokeObjectURL(url);
        }, 1000);
      };

      const canvas = document.createElement('canvas');
      canvas.width = 320;
      canvas.height = 240;
      const ctx = canvas.getContext('2d');
      
      videoCaptureInterval = setInterval(() => {
        if (!videoRecording) {
          clearInterval(videoCaptureInterval);
          return;
        }
        ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
        canvas.toBlob((blob) => {
          if (blob && videoSocket.readyState === WebSocket.OPEN) {
            console.log("Sending captured video frame blob, size:", blob.size);
            videoSocket.send(blob);
          } else {
            console.warn("Blob is null or videoSocket not open.");
          }
        }, 'image/jpeg');
      }, 1000);
      
      videoRecordBtn.innerText = 'Stop Video Recording';
      videoRecording = true;
    }

    function stopVideoStream() {
      if (videoCaptureInterval) {
        clearInterval(videoCaptureInterval);
      }
      if (videoSocket && videoSocket.readyState === WebSocket.OPEN) {
        videoSocket.close();
      }
      videoRecordBtn.innerText = 'Start Video Recording';
      videoStatus.innerText = 'Video streaming stopped.';
      if (videoStream) {
        videoStream.getTracks().forEach(track => track.stop());
      }
      if (videoElement) {
        videoElement.pause();
        videoElement.srcObject = null;
      }
      processedFrame.src = '';
      videoRecording = false;
    }

    videoRecordBtn.addEventListener('click', async () => {
      if (!videoRecording) {
        await startVideoStream();
      } else {
        stopVideoStream();
      }
    });
  </script>
</body>
</html>
