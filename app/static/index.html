<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>UNBLIND</title>
</head>
<body>
  <h1>UNBLIND</h1>
  
  <!-- Voice Recording Section -->
  <section>
    <h2>Voice Recording (WebSocket Streaming)</h2>
    <button id="voiceRecordBtn">Start Voice Recording</button>
    <p id="voiceStatus"></p>
    <h3>Transcription:</h3>
    <div id="transcriptionOutput" style="border:1px solid #ccc; padding: 8px; min-height: 40px;"></div>
  </section>
  
  <!-- Video Recording Section -->
  <section>
    <h2>Video Recording (WebSocket Streaming)</h2>
    <button id="videoRecordBtn">Start Video Recording</button>
    <p id="videoStatus"></p>
    <h3>Processed Video Frame:</h3>
    <img id="processedFrame" width="320" height="240" alt="Processed Video Frame" style="border:1px solid #ccc;">
  </section>
  
  <script>
    // Voice recording logic with stop/restart cycle for finalized segments
    let voiceRecorder;
    let voiceRecording = false;
    let voiceSocket; // WebSocket for audio streaming
    let voiceStream;

    const voiceRecordBtn = document.getElementById('voiceRecordBtn');
    const voiceStatus = document.getElementById('voiceStatus');
    const transcriptionOutput = document.getElementById('transcriptionOutput');

    voiceRecordBtn.addEventListener('click', async () => {
      if (!voiceRecording) {
        // Request audio stream once
        voiceStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        // Open WebSocket connection to the backend endpoint
        voiceSocket = new WebSocket('ws://127.0.0.1:8000/ws/stream_audio');
        voiceSocket.onopen = () => {
          console.log('Voice WebSocket connection opened');
          voiceStatus.innerText = 'Streaming audio...';
        };
        voiceSocket.onerror = (err) => {
          console.error('Voice WebSocket error: ', err);
          voiceStatus.innerText = 'Error in audio stream.';
        };
        voiceSocket.onclose = () => {
          console.log('Voice WebSocket connection closed');
        };
        // Listen for transcription messages from the server
        voiceSocket.onmessage = (event) => {
          transcriptionOutput.innerText = event.data;
        };
        
        voiceRecording = true;
        voiceRecordBtn.innerText = 'Stop Voice Recording';
        startVoiceRecordingCycle();
      } else {
        // Stop the cycle and close the WebSocket
        voiceRecording = false;
        if (voiceRecorder && voiceRecorder.state !== "inactive") {
          voiceRecorder.stop();
        }
        if (voiceSocket && voiceSocket.readyState === WebSocket.OPEN) {
          voiceSocket.close();
        }
        voiceRecordBtn.innerText = 'Start Voice Recording';
        voiceStatus.innerText = 'Audio streaming stopped.';
      }
    });

    // This function starts a recording cycle that records for a fixed duration (e.g., 3 seconds),
    // stops to finalize the blob, sends it over the WebSocket, then restarts if recording is still active.
    function startVoiceRecordingCycle() {
      if (!voiceRecording) return;
      
      // Specify MIME type explicitly to encourage a complete container.
      voiceRecorder = new MediaRecorder(voiceStream, { mimeType: "audio/webm;codecs=opus" });
      
      voiceRecorder.ondataavailable = (event) => {
        if (event.data.size > 0 && voiceSocket.readyState === WebSocket.OPEN) {
          voiceSocket.send(event.data);
        }
      };

      // Restart the cycle when the recorder stops.
      voiceRecorder.onstop = () => {
        if (voiceRecording) {
          setTimeout(startVoiceRecordingCycle, 200);
        }
      };

      // Record for 3 seconds
      voiceRecorder.start();
      setTimeout(() => {
        if (voiceRecorder.state === "recording") {
          voiceRecorder.stop();
        }
      }, 3000);
    }

    // Video recording logic with WebSocket streaming (unchanged)
    let videoRecorder;
    let videoRecording = false;
    let videoSocket; // WebSocket for video streaming
    let videoStream;

    const videoRecordBtn = document.getElementById('videoRecordBtn');
    const videoStatus = document.getElementById('videoStatus');
    const processedFrame = document.getElementById('processedFrame');

    videoRecordBtn.addEventListener('click', async () => {
      if (!videoRecording) {
        videoStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        videoSocket = new WebSocket('ws://127.0.0.1:8000/ws/stream_video');
        videoSocket.onopen = () => {
          console.log('Video WebSocket connection opened');
          videoStatus.innerText = 'Streaming video...';
        };
        videoSocket.onerror = (err) => {
          console.error('Video WebSocket error: ', err);
          videoStatus.innerText = 'Error in video stream.';
        };
        videoSocket.onclose = () => {
          console.log('Video WebSocket connection closed');
        };

        videoSocket.onmessage = (event) => {
          const blob = new Blob([event.data], { type: 'image/jpeg' });
          const url = URL.createObjectURL(blob);
          processedFrame.src = url;
          setTimeout(() => {
            URL.revokeObjectURL(url);
          }, 100);
        };

        videoRecorder = new MediaRecorder(videoStream);
        videoRecorder.ondataavailable = (e) => {
          if (e.data.size > 0 && videoSocket.readyState === WebSocket.OPEN) {
            videoSocket.send(e.data);
          }
        };
        videoRecorder.start(1000);
        videoRecordBtn.innerText = 'Stop Video Recording';
        videoRecording = true;
      } else {
        videoRecorder.stop();
        if (videoSocket && videoSocket.readyState === WebSocket.OPEN) {
          videoSocket.close();
        }
        videoRecordBtn.innerText = 'Start Video Recording';
        videoStatus.innerText = 'Video streaming stopped.';
        videoStream.getTracks().forEach(track => track.stop());
        processedFrame.src = '';
        videoRecording = false;
      }
    });
  </script>
</body>
</html>
